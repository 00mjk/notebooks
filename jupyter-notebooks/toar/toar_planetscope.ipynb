{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting PlanetScope Imagery from Radiance to Reflectance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planet Labs' analytic data products (both Rapideye and Dove) are reported in units of radiance: $W*m^{-2}*sr^{-1}$. That means that every pixel in an analytic tiff has a natural language interpretation: \"How much light was captured over this spot of ground?\"\n",
    "\n",
    "But over the course of a day or year, the number of photons that the sun shines on the scene rises and falls. If you naively compare the radiance values of two scenes over the same spot on Earth from the same satellite but a few weeks (or even just hours!) apart, you will likely find dramatic radiance differences **even if nothing on the ground has changed!**\n",
    "\n",
    "In addition to this variation, each of Planet Labs' 150+ satllites have small amounts of variation in their spectral filters which yields slight differences in radiance measurements, even from two satellites taking pictures of the same exact place at the same exact moment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Illumination](illumination.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct all this radiance variation you would have to do a lot of math using the exact location and local time of day to find the angle to the sun and sun-earth distance, then compute a solar irradiance model to estimate how many photons of each band are present in the image, and finally convolve that spectrum with the spectral response of the individual satellite to yield the number of photons of each band that are actually recorded by that sensor. Dividing by this number normalizes the measured brightness to the brightness of the sun at that time and place through that particular filter, yielding a much more comparable number: reflectance.\n",
    "\n",
    "Top of Atmosphere Reflectance is extremely useful because it is an apples-to-apples comparable number from any satellite over any location that does not change with time of day or time of year **unless the content of the scene changes.** It is very commonly used in GIS applications which compute spectral indices such as NDVI or NDWI. \n",
    "\n",
    "It is so broadly useful that Planet does this math for you and provides all the coefficients necessary to convert a radiance image into a reflectance image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{img}_{reflectance} =  \\begin{vmatrix}\n",
    "a \\\\\n",
    "b \\\\\n",
    "c \\\\\n",
    "d \n",
    "\\end{vmatrix}\n",
    "\\times \\mathbf{img}_{radiance}\n",
    "\\end{equation*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four coefficients $a, b, c, d$ are calculated and provided with every analytic image that Planet provides and can be used as simple scaling factors to convert from radiance to reflectance. Their values change with the image's local \n",
    "time of day and time of year, and do so uniquely per satellite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this guide, you'll perform a basic Radiance to Reflectance calculation on PlanetScope imagery using just a few lines of Python. Here are the steps:**\n",
    "\n",
    "1. Download a PlanetScope image\n",
    "2. Extract data from each spectral band\n",
    "3. Extract the coefficients\n",
    "4. Convert Radiance to Reflectance\n",
    "5. Save the Reflectance\n",
    "6. Apply a color scheme to visualize reflectance on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "- Python 2.7 or 3+\n",
    "- [Planet's Python Client](https://www.planet.com/docs/api-quickstart-examples/cli/)\n",
    "- [rasterio](https://github.com/mapbox/rasterio)\n",
    "- [numpy](http://www.numpy.org/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [Planet API Key](https://www.planet.com/account/#/), stored as environment variable `$PL_API_KEY`.\n",
    "- [Planet 4-Band Imagery](https://www.planet.com/docs/imagery-quickstart/) with the following specifications: `item-type`: `PSOrthoTile`, `REOrthoTile`, or `PSScene4Band`; `asset-type`: `analytic`, or `basic_analytic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Download a PlanetScope Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you're going to download a [4-band PlanetScope satellite image](https://www.planet.com/docs/spec-sheets/sat-imagery/#ps-imagery-product) of agricultural land in California's Central Valley, captured in mid July 2017 (`item-id`: `20170623_180038_0f34`). You can do this using [Planet's Python client](https://www.planet.com/docs/api-quickstart-examples/cli/) to interact with our Data API, or by browsing [Planet Explorer](https://www.planet.com/products/explorer/), filtering for 4 Band PlanetScope scene (`PSScene4Band`) or Planetscope ortho tile (`PSOrthoTile`), and downloading an `analytic` asset.\n",
    "\n",
    "Before you download the full image, you can [preview a thumbnail](https://www.planet.com/docs/reference/data-api/previews/) of the image via Planet's Data API. (The thumbnails are 256x256 by default, and can be scaled up by passing in a `width` parameter.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://api.planet.com/data/v1/item-types/PSScene4Band/items/20170623_180038_0f34/thumb?width=512\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://api.planet.com/data/v1/item-types/PSScene4Band/items/20170623_180038_0f34/thumb?width=512\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll use [Planet's Python client](https://planetlabs.github.io/planet-client-python/index.html) to download the image. *Note: when you run this command, you'll get a stream of messages in your Jupyter notebook as the Python client polls the Data API to determine if the image is [activated and ready to download](https://www.planet.com/docs/api-quickstart-examples/step-2-download/#activate).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!planet data download --item-type PSScene4Band --asset-type analytic,analytic_xml --string-in id 20170623_180038_0f34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You now have two files in your download directory: `20170623_180038_0f34_3B_AnalyticMS.tif` and `20170623_180038_0f34_3B_AnalyticMS_metadata.xml`. The first file is a GeoTIFF, the image you requested with spatial reference data embedded. The second file is a metadata file for that image that includes the data you'll need to convert from radiance to reflectance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Extract the Data from Each Spectral Band "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, you'll use [Rasterio](https://github.com/mapbox/rasterio), a Python library for reading and writing geospatial raster datasets, to open the raster image you downloaded (the .tif file). Then you'll extract the data from the red and near-infrared bands and load the band data into arrays that you can manipulate using Python's [NumPy](http://www.numpy.org/) libary. *Note: in PlanetScope 4-band images, the band order is BGRN: (1) Blue, (2) Green, (3) Red, (4) Near-infrared.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "filename = \"20170623_180038_0f34_3B_AnalyticMS.tif\"\n",
    "\n",
    "# Load red and NIR bands - note all PlanetScope 4-band images have band order BGRN\n",
    "with rasterio.open(filename) as src:\n",
    "    band_blue_radiance = src.read(1)\n",
    "    \n",
    "with rasterio.open(filename) as src:\n",
    "    band_green_radiance = src.read(2)\n",
    "\n",
    "with rasterio.open(filename) as src:\n",
    "    band_red_radiance = src.read(3)\n",
    "\n",
    "with rasterio.open(filename) as src:\n",
    "    band_nir_radiance = src.read(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Extract the Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can convert to reflectance, you must extract the conversion coefficients from the metadata file you downloaded (the .xml file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "\n",
    "xmldoc = minidom.parse(\"20170623_180038_0f34_3B_AnalyticMS_metadata.xml\")\n",
    "nodes = xmldoc.getElementsByTagName(\"ps:bandSpecificMetadata\")\n",
    "\n",
    "# XML parser refers to bands by numbers 1-4\n",
    "coeffs = {}\n",
    "for node in nodes:\n",
    "    bn = node.getElementsByTagName(\"ps:bandNumber\")[0].firstChild.data\n",
    "    if bn in ['1', '2', '3', '4']:\n",
    "        i = int(bn)\n",
    "        value = node.getElementsByTagName(\"ps:reflectanceCoefficient\")[0].firstChild.data\n",
    "        coeffs[i] = float(value)\n",
    "\n",
    "print \"Conversion coefficients:\", coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the coefficients are all of order `1e-5`, and that the coefficient for NIR is significantly higher than the coefficient for blue. This is a big deal if your use case involves performing band math because a pixel with a `NIR/blue` ratio of `1.0` in the radiance image will have a `NIR/blue` ratio of `3.35/1.929=1.73` in the reflectance image!\n",
    "\n",
    "Most spectral indices are defined in terms of reflectance, not radiance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert Radiance to Reflectance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiance is measured in SI units: W/m^2. Reflectance is a ratio from 0 to 1. The conversion is performed as a simple per-band scalar multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red band radiance is from 0 to 24764\n",
      "Red band reflectance is from 0.0 to 0.562714954836\n"
     ]
    }
   ],
   "source": [
    "# Multiply the Digital Number (DN) values in each band by the TOA reflectance coefficients\n",
    "band_blue_reflectance = band_blue_radiance * coeffs[1]\n",
    "band_green_reflectance = band_green_radiance * coeffs[2]\n",
    "band_red_reflectance = band_red_radiance * coeffs[3]\n",
    "band_nir_reflectance = band_nir_radiance * coeffs[4]\n",
    "\n",
    "import numpy as np\n",
    "print \"Red band radiance is from {} to {}\".format(np.amin(band_red_radiance), np.amax(band_red_radiance))\n",
    "print \"Red band reflectance is from {} to {}\".format(np.amin(band_red_reflectance), np.amax(band_red_reflectance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Save the Reflectance Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you're going to save the calculated reflectance values to a new image file, making sure the new image file has the same geospatial metadata as the original GeoTIFF we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Scaling, red band reflectance is from 0.0 to 0.562714954836\n",
      "After Scaling, red band reflectance is from 0.0 to 5627.14954836\n"
     ]
    }
   ],
   "source": [
    "# Set spatial characteristics of the output object to mirror the input\n",
    "kwargs = src.meta\n",
    "kwargs.update(\n",
    "    dtype=rasterio.uint16,\n",
    "    count = 4)\n",
    "\n",
    "print \"Before Scaling, red band reflectance is from {} to {}\".format(np.amin(band_red_reflectance), np.amax(band_red_reflectance))\n",
    "\n",
    "# Here we include a fixed scaling factor. This is common practice.\n",
    "scale = 10000\n",
    "blue_ref_scaled = scale * band_blue_reflectance\n",
    "green_ref_scaled = scale * band_green_reflectance\n",
    "red_ref_scaled = scale * band_red_reflectance\n",
    "nir_ref_scaled = scale * band_nir_reflectance\n",
    "\n",
    "print \"After Scaling, red band reflectance is from {} to {}\".format(np.amin(red_ref_scaled), np.amax(red_ref_scaled))\n",
    "\n",
    "# Write band calculations to a new raster file\n",
    "with rasterio.open('reflectance.tif', 'w', **kwargs) as dst:\n",
    "        dst.write_band(1, band_blue_reflectance.astype(rasterio.uint16))\n",
    "        dst.write_band(2, band_green_reflectance.astype(rasterio.uint16))\n",
    "        dst.write_band(3, band_red_reflectance.astype(rasterio.uint16))\n",
    "        dst.write_band(4, band_nir_reflectance.astype(rasterio.uint16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This warrants some explanation: Reflectance is generally defined as a floating point number between 0 and 1, but image file formats are much more commonly stored as unsigned integers. A common practice in the industry is to multiply the radiance value by 10,000, then save the result as a file with data type uint16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Apply a Color Scheme to Visualize the Reflectance Values on the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, you'll use [Matplotlib](https://matplotlib.org/) to visualize the reflectance values you calculated for the PlanetScope scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\"\"\"\n",
    "The reflectance values will range from 0 to 1. You want to use a diverging color scheme to visualize the data,\n",
    "and you want to center the colorbar at a defined midpoint. The class below allows you to normalize the colorbar.\n",
    "\"\"\"\n",
    "\n",
    "class MidpointNormalize(colors.Normalize):\n",
    "    \"\"\"\n",
    "    Normalise the colorbar so that diverging bars work there way either side from a prescribed midpoint value)\n",
    "    e.g. im=ax1.imshow(array, norm=MidpointNormalize(midpoint=0.,vmin=-100, vmax=100))\n",
    "    Credit: Joe Kington, http://chris35wills.github.io/matplotlib_diverging_colorbar/\n",
    "    \"\"\"\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        # I'm ignoring masked values and all kinds of edge cases to make a\n",
    "        # simple example...\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y), np.isnan(value))\n",
    "\n",
    "\n",
    "# Set min/max values from reflectance range for image (excluding NAN)\n",
    "min=np.nanmin(band_nir_reflectance)\n",
    "max=np.nanmax(band_nir_reflectance)\n",
    "mid=0.20\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# diverging color scheme chosen from https://matplotlib.org/users/colormaps.html\n",
    "# note that appending '_r' to the color scheme name reverses it!\n",
    "cmap = plt.cm.get_cmap('RdGy_r')\n",
    "\n",
    "cax = ax.imshow(band_nir_reflectance, cmap=cmap, clim=(min, max), norm=MidpointNormalize(midpoint=mid,vmin=min, vmax=max))\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_title('NIR Reflectance', fontsize=18, fontweight='bold')\n",
    "\n",
    "cbar = fig.colorbar(cax, orientation='horizontal', shrink=0.65)\n",
    "\n",
    "fig.savefig(\"ref-fig.png\", dpi=200, bbox_inches='tight', pad_inches=0.7)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the NIR reflectance image, we see that the lakes and ponds appear to reflect almost no infrared light at all, but the healthy fields reflect almost 50% of the incoming infrared light!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
