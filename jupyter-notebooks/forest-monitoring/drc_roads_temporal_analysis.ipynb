{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRC Roads Temporal Analysis\n",
    "\n",
    "\n",
    "\n",
    "Keywords: temporal analysis, forest monitoring, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from planet import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functionality from local notebooks\n",
    "from ipynb.fs.defs.drc_roads_download import get_overlapping_scenes, StripDownloader, StripSearcher\n",
    "from ipynb.fs.defs.drc_roads_classification \\\n",
    "    import Timer, load_training_data, classify_forest, classified_band_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Scenes\n",
    "\n",
    "In this section, we use the ipynb module to import `StripDownloader` from the [drc_roads_download](drc_roads_download.ipynb) notebook. We then use `StripDownloader` to download the portion of OrthoTile strips that overlap the AOI.\n",
    "\n",
    "### Load data from drc_roads_download notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load aoi. Saved in drc_roads_download notebook\n",
    "aoi_geojson_filename = os.path.join('pre-data', 'aoi.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download portions of OrthoTile strips that overlap AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create planet api client\n",
    "planet_api_key = os.environ['PL_API_KEY']\n",
    "\n",
    "# quick check that key is defined\n",
    "assert planet_api_key, \"PL_API_KEY not defined.\"\n",
    "\n",
    "client = api.ClientV1(api_key=planet_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load aoi json\n",
    "with open(aoi_geojson_filename) as json_data:\n",
    "    aoi = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 OrthoTiles were returned from the api search.\n",
      "There are 494 OrthoTiles that overlap aoi.\n",
      "There are 144 OrthoTiles in 36 strips that significantly overlap the aoi.\n",
      "36 strips\n",
      "found data/1214499_udm_mosaic.tif\n",
      "found data/1176905_udm_mosaic.tif\n",
      "found data/1167439_udm_mosaic.tif\n",
      "found data/1153620_udm_mosaic.tif\n",
      "found data/1150329_udm_mosaic.tif\n",
      "found data/1130991_udm_mosaic.tif\n",
      "found data/1127986_udm_mosaic.tif\n",
      "found data/1124454_udm_mosaic.tif\n",
      "found data/1121892_udm_mosaic.tif\n",
      "found data/1114901_udm_mosaic.tif\n",
      "found data/1043874_udm_mosaic.tif\n",
      "found data/1091588_udm_mosaic.tif\n",
      "found data/1085449_udm_mosaic.tif\n",
      "found data/1081381_udm_mosaic.tif\n",
      "found data/1054596_udm_mosaic.tif\n",
      "found data/1047845_udm_mosaic.tif\n",
      "found data/1043827_udm_mosaic.tif\n",
      "found data/1037433_udm_mosaic.tif\n",
      "found data/1011123_udm_mosaic.tif\n",
      "found data/993122_udm_mosaic.tif\n",
      "found data/960830_udm_mosaic.tif\n",
      "found data/943459_udm_mosaic.tif\n",
      "found data/904538_udm_mosaic.tif\n",
      "found data/915538_udm_mosaic.tif\n",
      "found data/883193_udm_mosaic.tif\n",
      "found data/879726_udm_mosaic.tif\n",
      "found data/863467_udm_mosaic.tif\n",
      "found data/758681_udm_mosaic.tif\n",
      "found data/741529_udm_mosaic.tif\n",
      "found data/739199_udm_mosaic.tif\n",
      "found data/705233_udm_mosaic.tif\n",
      "found data/699281_udm_mosaic.tif\n",
      "found data/651530_udm_mosaic.tif\n",
      "found data/666617_udm_mosaic.tif\n",
      "found data/636659_udm_mosaic.tif\n",
      "found data/624045_udm_mosaic.tif\n",
      "Nothing to download\n",
      "Filtered to 21 strips out of 36 strips.\n",
      "84 OrthoTiles found\n"
     ]
    }
   ],
   "source": [
    "# get good overlapping scenes from to July 2017 to February 2018\n",
    "begin=datetime.datetime(year=2017,month=7,day=1)\n",
    "end=datetime.datetime(year=2018,month=3,day=1)\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(aoi_geojson_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 strips\n",
      "found data/1176905_analytic_mosaic.tif\n",
      "found data/1153620_analytic_mosaic.tif\n",
      "found data/1130991_analytic_mosaic.tif\n",
      "found data/1127986_analytic_mosaic.tif\n",
      "found data/1124454_analytic_mosaic.tif\n",
      "found data/1121892_analytic_mosaic.tif\n",
      "found data/1114901_analytic_mosaic.tif\n",
      "found data/1091588_analytic_mosaic.tif\n",
      "found data/1085449_analytic_mosaic.tif\n",
      "found data/1081381_analytic_mosaic.tif\n",
      "found data/1047845_analytic_mosaic.tif\n",
      "found data/1043827_analytic_mosaic.tif\n",
      "found data/1037433_analytic_mosaic.tif\n",
      "found data/943459_analytic_mosaic.tif\n",
      "found data/758681_analytic_mosaic.tif\n",
      "found data/741529_analytic_mosaic.tif\n",
      "found data/739199_analytic_mosaic.tif\n",
      "found data/699281_analytic_mosaic.tif\n",
      "found data/651530_analytic_mosaic.tif\n",
      "found data/666617_analytic_mosaic.tif\n",
      "found data/636659_analytic_mosaic.tif\n",
      "Nothing to download\n"
     ]
    }
   ],
   "source": [
    "asset_type = 'analytic'\n",
    "strip_downloader = StripDownloader(good_scenes, aoi_geojson_filename, client)\n",
    "strip_downloader.run(asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get mosaic image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort strip ids as integers. Strip id order is the same as strip temporal order\n",
    "strip_ids = [int(s) for s in good_scenes.strip_id.unique().tolist()]\n",
    "strip_ids.sort()\n",
    "strip_ids = [str(s) for s in strip_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_mosaics = [strip_downloader.get_filename(i, asset_type) for i in strip_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/636659_analytic_mosaic.tif',\n",
       " 'data/651530_analytic_mosaic.tif',\n",
       " 'data/666617_analytic_mosaic.tif',\n",
       " 'data/699281_analytic_mosaic.tif',\n",
       " 'data/739199_analytic_mosaic.tif',\n",
       " 'data/741529_analytic_mosaic.tif',\n",
       " 'data/758681_analytic_mosaic.tif',\n",
       " 'data/943459_analytic_mosaic.tif',\n",
       " 'data/1037433_analytic_mosaic.tif',\n",
       " 'data/1043827_analytic_mosaic.tif',\n",
       " 'data/1047845_analytic_mosaic.tif',\n",
       " 'data/1081381_analytic_mosaic.tif',\n",
       " 'data/1085449_analytic_mosaic.tif',\n",
       " 'data/1091588_analytic_mosaic.tif',\n",
       " 'data/1114901_analytic_mosaic.tif',\n",
       " 'data/1121892_analytic_mosaic.tif',\n",
       " 'data/1124454_analytic_mosaic.tif',\n",
       " 'data/1127986_analytic_mosaic.tif',\n",
       " 'data/1130991_analytic_mosaic.tif',\n",
       " 'data/1153620_analytic_mosaic.tif',\n",
       " 'data/1176905_analytic_mosaic.tif']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_mosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Scenes\n",
    "\n",
    "In this section, we use the ipynb module to import classification functionality from the [drc_roads_classification](drc_roads_classification.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/636659_analytic_mosaic.tif'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_mosaics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_bands_file = os.path.join('data', 'classified_bands.npz')\n",
    "\n",
    "def save_to_cache(classified_bands, strip_ids):\n",
    "    save_bands = dict((s, classified_bands[s])\n",
    "                      for s in strip_ids)\n",
    "    # masked arrays are saved as just arrays, so save mask for later\n",
    "    save_bands.update(dict((s+'_msk', classified_bands[s].mask)\n",
    "                           for s in strip_ids))\n",
    "    np.savez_compressed(classified_bands_file, **save_bands)  \n",
    "\n",
    "def load_from_cache():\n",
    "    tmp_cls = np.load(classified_bands_file)\n",
    "    sids = [k for k in tmp_cls.keys() if not k.endswith('_msk')]\n",
    "    # reform masked array from saved array and saved mask\n",
    "    classified_bands = dict((s, np.ma.array(tmp_cls[s], mask=tmp_cls[s+'_msk']))\n",
    "                            for s in sids)\n",
    "    return classified_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_cache(classified_bands, strip_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached classified bands\n"
     ]
    }
   ],
   "source": [
    "use_cache = True\n",
    "\n",
    "if use_cache and os.path.isfile(classified_bands_file):\n",
    "    print('using cached classified bands')\n",
    "    test_classified_bands = load_from_cache()\n",
    "else:\n",
    "    X_training, y_training = load_training_data()\n",
    "    with Timer():\n",
    "        def classify(sid):\n",
    "            img = strip_downloader.get_filename(sid, asset_type)\n",
    "            # we only have two values, 0 and 1. Convert to uint8 for memory\n",
    "            band = (classify_forest(img, X_training, y_training)).astype(np.uint8)\n",
    "            return band\n",
    "\n",
    "        classified_bands = dict((s, classify(s)) for s in strip_ids)\n",
    "    \n",
    "    # save to cache\n",
    "    save_to_cache(classified_bands, strip_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Classified Scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# load local visual module\n",
    "# autoreload because visual is in development\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decimate classified arrays for memory conservation\n",
    "def decimate(arry, num=8):\n",
    "    return arry[::num, ::num].copy()\n",
    "\n",
    "do_visualize = False # set to True to view images\n",
    "if do_visualize:\n",
    "    for strip_id, classified_band in test_classified_bands.items():\n",
    "        visual.plot_image(classified_band_to_rgb(decimate(classified_band)),\n",
    "                          title='Classified Image ({})'.format(strip_id),\n",
    "                          figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of classification in these images is mixed. There are a few images where the UDM fails to identify clouds (e.g. 1114901) and few images where the results actually look pretty good but classification missfires and classifies everything as non-forest (e.g. 1091588). There may be uniform in the imagery that makes it brighter than usual, which causes the classifier to fail. Ultimately, visual inspection finds that about 8 of the 21 classified images looks informative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Classification\n",
    "\n",
    "Lets look at the time series information for each pixel and see if we can identify true change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strip_date(strip_id):\n",
    "    strip_scenes = overlapping_scenes[overlapping_scenes.strip_id == strip_id]\n",
    "    strip_dates = set([a.date() for a in strip_scenes.acquired.tolist()])\n",
    "    assert len(strip_dates) == 1\n",
    "    return strip_dates.pop()\n",
    "\n",
    "test_strip_id = '943459'\n",
    "get_strip_date(test_strip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time series for each unmasked pixel\n",
    "pixel_timeseries = np.ma.compress_cols(np.ma.dstack(classified_bands).transpose(2, 0, 1).reshape(9, -1)).transpose(1,0)\n",
    "pixel_timeseries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(pixels, count):\n",
    "    pixel_sample = pixels.copy()\n",
    "    np.random.shuffle(pixel_sample) # only shuffles along the first axis\n",
    "    pixel_sample = pixel_sample[:count, :]\n",
    "    return pixel_sample\n",
    "\n",
    "make_sample(pixel_timeseries, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_same_size_samples(list_of_pixel_sets):\n",
    "    sample_len = min([p.shape[0] for p in list_of_pixel_sets])\n",
    "\n",
    "    def sample_pixels(pixels):\n",
    "        if pixels.shape[0] > sample_len:\n",
    "            pixel_sample = make_sample(pixels, sample_len)\n",
    "        else:\n",
    "            pixel_sample = pixels\n",
    "        return pixel_sample\n",
    "    \n",
    "    return [sample_pixels(p)\n",
    "            for p in list_of_pixel_sets]\n",
    "\n",
    "forest_pixels = pixel_timeseries[pixel_timeseries[:,0] == 0]\n",
    "non_forest_pixels = pixel_timeseries[pixel_timeseries[:,0] == 1]\n",
    "forest_pixels_sample, non_forest_pixels_sample = make_same_size_samples([forest_pixels, non_forest_pixels])\n",
    "print(forest_pixels_sample.shape)\n",
    "print(non_forest_pixels_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_plot_sample = make_sample(forest_pixels_sample, 6)\n",
    "non_forest_plot_sample = make_sample(non_forest_pixels_sample, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, pixel in enumerate(forest_plot_sample):\n",
    "    plt.plot(np.array(range(len(pixel))), pixel, 'o--', label=i)\n",
    "# plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i, pixel in enumerate(non_forest_plot_sample):\n",
    "    plt.plot(np.array(range(len(pixel))), pixel, 'o--', label=i)\n",
    "# plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
