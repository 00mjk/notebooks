{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset for DRC Road Classification\n",
    "\n",
    "The Random Forest Classifier used the [drc_roads_classification](drc_roads_classification.ipynb) notebook requires a training dataset. In this notebook, we create the training dataset from pre-created label images. These label images were created in [GIMP](https://www.gimp.org/) using manual labeling of road and forest regions in a small region of the OrthoTile strip AOI image created in [drc_roads_classification](drc_roads_classification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from skimage import feature, filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled images, generated in GIMP, along with cropped OrthoTile as source image\n",
    "data_dir = 'pre-data'\n",
    "forest_image_filename = os.path.join(data_dir, 'mosaic_crop_forest.tif')\n",
    "road_image_filename = os.path.join(data_dir, 'mosaic_crop_road.tif')\n",
    "bands_image_filename = os.path.join(data_dir, 'mosaic_crop.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare feature bands\n",
    "\n",
    "All of the code in this section was copied from the [drc_roads_classification](drc_roads_classification.ipynb) notebook. It is necessary that the processing for the training dataset be the same as the processing for the prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_4band(filename):\n",
    "    with rasterio.open(filename, 'r') as src:\n",
    "        # orthotile band ordering: blue, green, red, nir\n",
    "        b, g, r, n = src.read() \n",
    "\n",
    "        mask = b == 0 # 0 is NoData\n",
    "\n",
    "    return [np.ma.array(band, mask=mask) for band in [b, g, r, n]]\n",
    "\n",
    "bands = load_4band(bands_image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texture_features(bands):\n",
    "    green_band = bands[1]\n",
    "    edges1 = feature.canny(green_band, low_threshold=0.0, high_threshold=0.01, sigma=2)\n",
    "    blurred = filters.gaussian(edges1, sigma=2)\n",
    "    blurred2 = filters.gaussian(edges1, sigma=6)\n",
    "    return [np.ma.array(texture_band, mask=green_band.mask)\n",
    "            for texture_band in (blurred, blurred2)]\n",
    "\n",
    "feature_bands = bands + get_texture_features(bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Label masks to features\n",
    "\n",
    "In this step, we load the images that represent the label masks for the forest / road classes, we then convert them to binary masks and apply them to the feature dataset to obtain two sets of data points: one set that contains features for the forest class, and another set that contains features for the road class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "578330\n",
      "17757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/rasterio/__init__.py:240: NotGeoreferencedWarning: Dataset has no geotransform set. Default transform will be applied (Affine.identity())\n",
      "  s = DatasetReader(fp, driver=driver, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load labeled images as boolean masks\n",
    "\n",
    "def get_label_mask(image_filename):\n",
    "    with rasterio.open(image_filename, 'r') as src:\n",
    "        band = src.read(1)\n",
    "        label_data = band == 0 # valid data in black regions\n",
    "        label_mask = ~label_data # mask True (masked) for not valid data\n",
    "    return label_mask\n",
    "\n",
    "def get_unmasked_count(mask):\n",
    "    return np.size(mask) - np.count_nonzero(mask)\n",
    "\n",
    "forest_mask = get_label_mask(forest_image_filename)\n",
    "print(get_unmasked_count(forest_mask))\n",
    "road_mask = get_label_mask(road_image_filename)\n",
    "print(get_unmasked_count(road_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply label masks to feature bands to get 2D array of feature values associated with\n",
    "# pixels of that label\n",
    "def get_label_pixels(label_mask, bands):\n",
    "    pixels = np.array([np.ma.array(b, mask=np.ma.mask_or(b.mask, label_mask)).compressed()\n",
    "                       for b in bands])\n",
    "    return pixels.swapaxes(0,1) # order by pixel then by band\n",
    "\n",
    "forest_pixels = get_label_pixels(forest_mask, feature_bands)\n",
    "road_pixels = get_label_pixels(road_mask, feature_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training datasets\n",
    "\n",
    "First, we create a balanced training set by using random sampling to create same-size samples of labeled pixels, then we create the X (features) and y (class) datasets in the format used by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17757, 6)\n",
      "(17757, 6)\n"
     ]
    }
   ],
   "source": [
    "def make_same_size_samples(list_of_pixels):\n",
    "    sample_len = min([p.shape[0] for p in list_of_pixels])\n",
    "\n",
    "    def sample_pixels(pixels):\n",
    "        if pixels.shape[0] > sample_len:\n",
    "            pixel_sample = pixels.copy()\n",
    "            np.random.shuffle(pixel_sample)\n",
    "            pixel_sample = pixel_sample[:sample_len]\n",
    "        else:\n",
    "            pixel_sample = pixels\n",
    "        return pixel_sample\n",
    "    \n",
    "    return [sample_pixels(p) for p in list_of_pixels]\n",
    "\n",
    "[forest_pixels_sample, road_pixels_sample] = \\\n",
    "    make_same_size_samples([forest_pixels, road_pixels])\n",
    "\n",
    "print(forest_pixels_sample.shape)\n",
    "print(road_pixels_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35514, 6)\n",
      "(35514,)\n"
     ]
    }
   ],
   "source": [
    "forest_label_value = 0\n",
    "road_label_value = 1\n",
    "X = np.concatenate((forest_pixels_sample, road_pixels_sample), axis=0)\n",
    "y = np.array(forest_pixels_sample.shape[0] * [forest_label_value] + \\\n",
    "             road_pixels_sample.shape[0] * [road_label_value])\n",
    "    \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file system\n",
    "output_file = os.path.join('pre-data', 'classification_training')\n",
    "np.savez(output_file, X=X, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
