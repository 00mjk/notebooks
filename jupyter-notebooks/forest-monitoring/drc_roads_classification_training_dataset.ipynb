{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset for DRC Road Classification\n",
    "\n",
    "The classifier used in DRC Roads analysis requires a training dataset.\n",
    "\n",
    "To create the training dataset, we first created the label images. These images were created in [GIMP](https://www.gimp.org/) using manual labeling of road and forest regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled images, generated in GIMP, along with cropped OrthoTile as source image\n",
    "data_dir = 'pre-data'\n",
    "forest_image_filename = os.path.join(data_dir, 'mosaic_crop_forest.tif')\n",
    "road_image_filename = os.path.join(data_dir, 'mosaic_crop_road.tif')\n",
    "bands_image_filename = os.path.join(data_dir, 'mosaic_crop.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare feature bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1309, 2201)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cropped orthotile as bands of pixels\n",
    "def read_4band(image_filename):\n",
    "    with rasterio.open(image_filename, 'r') as src:\n",
    "        bands = src.read()\n",
    "    return bands\n",
    "\n",
    "bands = read_4_band(bands_image_filename)\n",
    "bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 2201)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate texture bands. this comes from drc_roads_classification\n",
    "def get_texture_bands(green_band):\n",
    "    def scale(band):\n",
    "        '''Scale band values to band data type max/min'''\n",
    "        def _normalize(b):\n",
    "            '''Normalize values to 0-1'''\n",
    "            return (b-b.min())/(b.max()-b.min())\n",
    "        \n",
    "        scaled_band = _normalize(band) * np.iinfo(band.dtype).max\n",
    "        return scaled_band.astype(band.dtype)\n",
    "\n",
    "    green_band_normalized = scale(green_band)\n",
    "\n",
    "    edges1 = feature.canny(green_band_normalized, sigma=2)\n",
    "    blurred = filters.gaussian(edges1, sigma=2)\n",
    "    blurred2 = filters.gaussian(edges1, sigma=6)\n",
    "    return [blurred, blurred2]\n",
    "\n",
    "green_band = bands[1, :]\n",
    "blurred, blurred2 = get_texture_bands(green_band)\n",
    "blurred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1309, 2201)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_bands = np.concatenate((bands, blurred[np.newaxis,:], blurred2[np.newaxis,:]), axis=0)\n",
    "feature_bands.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Label masks to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2881109\n",
      "578330\n",
      "17757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/rasterio/__init__.py:240: NotGeoreferencedWarning: Dataset has no geotransform set. Default transform will be applied (Affine.identity())\n",
      "  s = DatasetReader(fp, driver=driver, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load labeled images as boolean masks\n",
    "\n",
    "def get_label_mask(image_filename):\n",
    "    with rasterio.open(image_filename, 'r') as src:\n",
    "        band = src.read(1)\n",
    "        label_data = band == 0 # valid data in black regions\n",
    "        label_mask = ~label_data # mask True (masked) for not valid data\n",
    "    return label_mask\n",
    "\n",
    "def get_unmasked_count(mask):\n",
    "    return np.size(mask) - np.count_nonzero(mask)\n",
    "\n",
    "print(forest_mask.size)\n",
    "forest_mask = get_label_mask(forest_image_filename)\n",
    "print(get_unmasked_count(forest_mask))\n",
    "road_mask = get_label_mask(road_image_filename)\n",
    "print(get_unmasked_count(road_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply label masks to orthotile bands to get 2D array of band values associated with\n",
    "# pixels of that label\n",
    "def get_label_pixels(label_mask, bands):\n",
    "    pixels = np.array([np.ma.array(b, mask=label_mask).compressed()\n",
    "                       for b in bands])\n",
    "    return pixels.swapaxes(0,1) # order by pixel then by band\n",
    "\n",
    "forest_pixels = get_label_pixels(forest_mask, feature_bands)\n",
    "road_pixels = get_label_pixels(road_mask, feature_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17757, 6)\n",
      "(17757, 6)\n"
     ]
    }
   ],
   "source": [
    "# for balanced training set, use random sampling to create same-size\n",
    "# samples of labeled pixels\n",
    "def make_same_size_samples(list_of_pixels):\n",
    "    sample_len = min([p.shape[0] for p in list_of_pixels])\n",
    "\n",
    "    def sample_pixels(pixels):\n",
    "        if pixels.shape[0] > sample_len:\n",
    "            pixel_sample = pixels.copy()\n",
    "            np.random.shuffle(pixel_sample)\n",
    "            pixel_sample = pixel_sample[:sample_len]\n",
    "        else:\n",
    "            pixel_sample = pixels\n",
    "        return pixel_sample\n",
    "    \n",
    "    return [sample_pixels(p) for p in list_of_pixels]\n",
    "\n",
    "[forest_pixels_sample, road_pixels_sample] = \\\n",
    "    make_same_size_samples([forest_pixels, road_pixels])\n",
    "\n",
    "print(forest_pixels_sample.shape)\n",
    "print(road_pixels_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35514, 6)\n",
      "(35514,)\n"
     ]
    }
   ],
   "source": [
    "forest_label_value = 0\n",
    "road_label_value = 1\n",
    "X = np.concatenate((forest_pixels_sample, road_pixels_sample), axis=0)\n",
    "y = np.array(forest_pixels_sample.shape[0] * [forest_label_value] + \\\n",
    "             road_pixels_sample.shape[0] * [road_label_value])\n",
    "    \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file system\n",
    "output_file = os.path.join('pre-data', 'classification_training')\n",
    "np.savez(output_file, X=X, y=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
