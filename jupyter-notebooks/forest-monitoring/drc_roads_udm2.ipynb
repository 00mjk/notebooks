{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRC Roads - UDM2\n",
    "\n",
    "In this notebook we compare the results of forest degredation detection using PSOrthotiles and UDM2 vs UDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from planet import api\n",
    "from planet.api import downloader, filters\n",
    "import rasterio\n",
    "from shapely import geometry as sgeom\n",
    "from shapely.ops import cascaded_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define AOI\n",
    "\n",
    "The AOI is a region in the Democratic Republic of Congo that experiences road development between September and November 2017. It is a rectangle that overlaps orthotile grid cell boundaries. Usually, we would redefine the AOI to be within an Orthotile, but we would lose a lot of context if we limited this AOI to only one Orthotile grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = {\"geometry\": {\n",
    "    \"type\":\"Polygon\",\n",
    "    \"coordinates\":\n",
    "        [[\n",
    "            [25.42429478260258,1.0255377823058893],\n",
    "            [25.592960813580472,1.0255377823058893],\n",
    "            [25.592960813580472,1.1196578801254304],\n",
    "            [25.42429478260258,1.1196578801254304],\n",
    "            [25.42429478260258,1.0255377823058893]\n",
    "        ]]}}\n",
    "\n",
    "item_type = 'PSOrthoTile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"25.417548141363465 1.0187911410667736 0.1821593134561219 0.10761338029777257\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,2.1451956624313198)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.003643186269122438\" opacity=\"0.6\" d=\"M 25.42429478260258,1.0255377823058893 L 25.592960813580472,1.0255377823058893 L 25.592960813580472,1.1196578801254304 L 25.42429478260258,1.1196578801254304 L 25.42429478260258,1.0255377823058893 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x7f0f49b70c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "aoi_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote AOI to pre-data/aoi.geojson\n"
     ]
    }
   ],
   "source": [
    "def create_save_dir(root_dir='data'):\n",
    "    save_dir = root_dir\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir\n",
    "\n",
    "def save_geojson_file(aoi_geojson, save_dir):\n",
    "    filename = os.path.join(save_dir, 'aoi.geojson')\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(aoi_geojson))\n",
    "    return filename\n",
    "\n",
    "geojson_filename = save_geojson_file(aoi, create_save_dir('pre-data'))\n",
    "print('wrote AOI to {}'.format(geojson_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Mosaic Multiple Strip Orthotile COGs\n",
    "\n",
    "This process is much like the process for downloading and mosaicing a single strip orthotile, but we want to trigger the download as soon as all scenes in a strip are activated. So this will require a bit of a change to the `on_complete()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StripDownloader(object):\n",
    "    def __init__(self, scenes, geojson_file, client, root_dir='data'):\n",
    "        self.scenes = scenes #pandas DataFrame describing scenes to download\n",
    "        self.geojson_file = geojson_file\n",
    "        self.client = client\n",
    "        self.save_dir = root_dir\n",
    "        \n",
    "        self.item_type = 'PSOrthoTile'\n",
    "\n",
    "        self.urls = dict() # this will be populated by on_complete()\n",
    "        self.strip_mosaics = [] # this will be populated by on_complete()\n",
    "        \n",
    "        self.strip_scenes = self._scenes_to_strip_scenes()\n",
    "    \n",
    "    def _scenes_to_strip_scenes(self):\n",
    "        strip_ids = self.scenes.strip_id.unique()\n",
    "        print('{} strips'.format(len(strip_ids)))\n",
    "        \n",
    "        strip_scenes = dict()\n",
    "        for sid in strip_ids:\n",
    "            strip_scenes[sid] = self.scenes[self.scenes['strip_id'] == sid].id.tolist()\n",
    "        return strip_scenes\n",
    "        \n",
    "\n",
    "    def get_on_complete(self, asset_type, verbose=False):\n",
    "        def on_complete(item, asset):\n",
    "            download_url = asset['location']\n",
    "            scene_id = item['id']\n",
    "            if verbose: print('{}'.format(scene_id))\n",
    "\n",
    "            strip_id = item['properties']['strip_id']\n",
    "            if self._completes_strip_scenes(strip_id, scene_id):\n",
    "                # do this after check that this scene_id completes a strip to avoid\n",
    "                # a race condition causing scene to be downloaded multiple times\n",
    "                self.urls[scene_id] = download_url\n",
    "            \n",
    "                output_file = self.get_filename(strip_id, asset_type)\n",
    "                self._download_strip_mosaic(strip_id, output_file, verbose)\n",
    "                self.strip_mosaics.append(output_file)\n",
    "            else:\n",
    "                self.urls[scene_id] = download_url\n",
    "\n",
    "        return on_complete\n",
    "\n",
    "    def _completes_strip_scenes(self, strip_id, scene_id):\n",
    "        activated_scenes_set = set(list(self.urls.keys()) + [scene_id])\n",
    "        strip_scenes_set = set(self.strip_scenes[strip_id])\n",
    "        return strip_scenes_set.intersection(activated_scenes_set) == strip_scenes_set\n",
    "    \n",
    "    def get_filename(self, strip_id, asset_type):\n",
    "        if not os.path.isdir(self.save_dir): os.makedirs(self.save_dir)\n",
    "        \n",
    "        filename = strip_id + '_' + asset_type + '_mosaic.tif'\n",
    "        filepath = os.path.join(self.save_dir, filename)\n",
    "        return filepath\n",
    "  \n",
    "    def _download_strip_mosaic(self, strip_id, output_file, verbose):\n",
    "        scene_ids = self.strip_scenes[strip_id]\n",
    "        download_urls = [self.urls[scene_id]\n",
    "                         for scene_id in scene_ids]\n",
    "\n",
    "        if verbose: print('downloading {} as {}'.format(scene_ids, output_file))\n",
    "        download_strip_aoi(download_urls, output_file, self.geojson_file, verbose=False)\n",
    "    \n",
    "    def run(self, asset_type, overwrite=False, verbose=False):\n",
    "        # filter scenes by those that already exist\n",
    "        if not overwrite:\n",
    "            dl_strip_scenes = self._filter_by_existing_strip_mosaics(self.strip_scenes,\n",
    "                                                                     asset_type,\n",
    "                                                                     verbose)\n",
    "        else:\n",
    "            dl_strip_scenes = self.strip_scenes\n",
    "\n",
    "        if len(dl_strip_scenes):\n",
    "            dl = downloader.create(self.client)\n",
    "            dl.on_complete = self.get_on_complete(asset_type, verbose=verbose)\n",
    "            dl.shutdown()\n",
    "            dl.activate(iter(self._get_items()), [asset_type])\n",
    "        elif verbose:\n",
    "            print('Nothing to download')\n",
    "    \n",
    "    def _filter_by_existing_strip_mosaics(self, strip_scenes, asset_type, verbose):\n",
    "        def _strip_mosaic_exists(strip_id):\n",
    "            strip_mosaic_filename = self.get_filename(strip_id, asset_type)\n",
    "            \n",
    "            found = False\n",
    "            if os.path.isfile(strip_mosaic_filename):\n",
    "                found = True\n",
    "                if verbose: print('found {}'.format(strip_mosaic_filename))\n",
    "            return found\n",
    "        \n",
    "        filtered_strip_ids = (s for s in strip_scenes.keys()\n",
    "                              if not _strip_mosaic_exists(s))\n",
    "        \n",
    "        filt_strip_scenes = {sid: strip_scenes[sid] for sid in filtered_strip_ids}\n",
    "        return filt_strip_scenes\n",
    "        \n",
    "    def _get_items(self):\n",
    "        return [self.client.get_item(self.item_type, sid).get()\n",
    "                for sid in self.scenes.id.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Scenes Based on Mosaic Scene Usefulness\n",
    "\n",
    "In this section, we create a scene search that filters scenes based on the percentage of useful pixels in the resulting mosaic scene, as determined from the Unusable Data Map (UDM), an asset available alongside the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading a UDM image and identifying binary representation as class labels\n",
    "def load_udm(udm_filename):\n",
    "    '''Load single-band bit-encoded UDM as a 2D array.'''\n",
    "    with rasterio.open(udm_filename, 'r') as src:\n",
    "        udm = src.read()[0,...]\n",
    "    return udm\n",
    "\n",
    "def get_udm_labels(udm):\n",
    "    '''Get the binary representation of the UDM values'''\n",
    "    return OrderedDict((v, '{0:08b}'.format(v)) for v in np.unique(udm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING HERE ON UDM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading a UDM2 image and\n",
    "# identifying binary representation as class labels\n",
    "def load_udm2(udm_filename):\n",
    "    '''Load multi-band UDM2 as a 2D array.\n",
    "    \n",
    "    band 1: clear map\n",
    "    band 2: snow map\n",
    "    band 3: shadow map\n",
    "    band 4: light haze map\n",
    "    band 5: heavy haze map\n",
    "    band 6: cloud map\n",
    "    band 7: confidence map (0-100)\n",
    "    band 8: usable pixels\n",
    "    '''\n",
    "    with rasterio.open(udm_filename, 'r') as src:\n",
    "        udm2 = None\n",
    "        for band_index in range(6):\n",
    "            band_num = band_index + 1\n",
    "            band = src.read(0)\n",
    "            if udm2 is None:\n",
    "                udm2 = np.array(band.shape, dtype=np.uint8)\n",
    "            udm2[band != 0] = band_num\n",
    "    return udm2\n",
    "\n",
    "def get_udm2_labels(udm):\n",
    "    '''Get the label for the UDM2 array values'''\n",
    "    labels = ['clear', 'snow', 'shadow', 'light haze', 'heavy haze', 'cloud']\n",
    "    return OrderedDict((v, labels[v]) for v in np.unique(udm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for searching using the Planet data api\n",
    "def search_pl_api(client, request, limit=500):\n",
    "    result = client.quick_search(request)\n",
    "    \n",
    "    # note that this returns a generator\n",
    "    return result.items_iter(limit=limit)\n",
    "\n",
    "def build_ps_request(aoi, item_type, begin, end):\n",
    "    search_aoi = aoi['geometry']\n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(search_aoi),\n",
    "        filters.range_filter('cloud_cover', lt=5),\n",
    "        filters.date_range('acquired', gte=begin),\n",
    "        filters.date_range('acquired', lt=end)\n",
    "    )\n",
    "\n",
    "    # build a request for only PlanetScope imagery\n",
    "    request = filters.build_search_request(\n",
    "        query, item_types=[item_type]\n",
    "    )\n",
    "    \n",
    "    return request\n",
    "\n",
    "def items_to_scenes(items):\n",
    "    '''convert data api item type to a pandas Dataframe with scene metadata'''\n",
    "    item_types = []\n",
    "\n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        \n",
    "        # add data not in properties list\n",
    "        props.update({\n",
    "            'thumbnail': item['_links']['thumbnail'],\n",
    "            'id': item['id'],\n",
    "            'footprint': item['geometry'],\n",
    "        })\n",
    "        return props\n",
    "    \n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    # convert acquired from string to datetime for processing\n",
    "    scenes['acquired'] = pd.to_datetime(scenes['acquired'])\n",
    "    \n",
    "    return scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for filtering based on scene overlap with aoi\n",
    "def aoi_intersection(footprint, aoi):\n",
    "    '''calculates the shape and percent of the intersection between\n",
    "    the footprint and the aoi as a pandas Series'''\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "    footprint_shape = sgeom.shape(footprint)\n",
    "    intersection_shape = aoi_shape.intersection(footprint_shape)\n",
    "\n",
    "    try:\n",
    "        intersection_percent = 100 * footprint_shape.area / intersection_shape.area\n",
    "    except ZeroDivisionError:\n",
    "        intersection_percent = 0\n",
    "\n",
    "    data = {'intersection_shape': intersection_shape,\n",
    "            'intersection_fp_perc': intersection_percent}\n",
    "    return pd.Series(data=data)\n",
    "\n",
    "def get_strip_aoi_inter(group, aoi):\n",
    "    '''\n",
    "    calculate strip intersection with aoi\n",
    "    \n",
    "    group: data frame with strip id as index\n",
    "    '''\n",
    "    intersections = group['intersection_shape'].tolist()\n",
    "    intersection_shape = cascaded_union(intersections)\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "\n",
    "    try:\n",
    "        intersection_percent = 100 * intersection_shape.area / aoi_shape.area\n",
    "    except ZeroDivisionError:\n",
    "        intersection_percent = 0 \n",
    "\n",
    "    data = {'strip_intersection_shape': intersection_shape,\n",
    "            'strip_intersection_aoi_perc': intersection_percent}\n",
    "    return pd.Series(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StripSearcher(object):\n",
    "    def __init__(self, aoi_geojson, begin, end, client, root_dir='data', udm_asset_type='udm'):\n",
    "        self.aoi = aoi_geojson # aoi geojson\n",
    "        self.begin = begin # datetime indicating begin date\n",
    "        self.end = end # datetime indicating end date\n",
    "        \n",
    "        self.client = client\n",
    "        self.save_dir = root_dir\n",
    "        \n",
    "        self.item_type = 'PSOrthoTile'\n",
    "        self.udm_asset_type = udm_asset_type\n",
    "        \n",
    "        self.overlapping_scenes = None # this is populated by get_overlapping_scenes()\n",
    "        self.good_scenes = None # this is populated by get_good_scenes()\n",
    "    \n",
    "    def search(self, geojson_filename=None, use_udm=True):\n",
    "        self.get_overlapping_scenes()\n",
    "        if use_udm:\n",
    "            if geojson_filename is None:\n",
    "                raise('Must specify geojson_filename')\n",
    "\n",
    "            good_strip_ids = self.get_good_strip_ids(geojson_filename)\n",
    "            all_strip_ids = self.get_strip_ids(self.overlapping_scenes)\n",
    "            print('Filtered to {} strips out of {} strips.'.format(\n",
    "                len(good_strip_ids), len(all_strip_ids)))\n",
    "            scenes = self.get_scenes_by_ids(good_strip_ids)\n",
    "        else:\n",
    "            scenes = self.overlapping_scenes\n",
    "        print('{} OrthoTiles found'.format(len(scenes)))\n",
    "        return scenes\n",
    "        \n",
    "    def get_overlapping_scenes(self):\n",
    "        # get all scenes that fit search\n",
    "        items = search_pl_api(self.client,\n",
    "                              build_ps_request(self.aoi, self.item_type, self.begin, self.end))\n",
    "        scenes = items_to_scenes(items)\n",
    "        print('{} OrthoTiles were returned from the api search.'.format(len(scenes)))\n",
    "        \n",
    "        # filter to scenes where footprint overlaps aoi\n",
    "        intersections = scenes.footprint.apply(aoi_intersection, args=(self.aoi,))\n",
    "        scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)\n",
    "        scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "        print('There are {} OrthoTiles that overlap aoi.'.format(len(scenes_inter)))\n",
    "        \n",
    "        # filter to scenes in strips that have significant overlap\n",
    "        scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "        strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=self.aoi)\n",
    "        strips_filt = strip_aoi_inter[strip_aoi_inter.strip_intersection_aoi_perc > 80]\n",
    "        \n",
    "        overlapping_strip_ids = strips_filt.index.tolist()\n",
    "        overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]  \n",
    "        print('There are {} OrthoTiles in {} strips that significantly overlap the aoi.'.format(\n",
    "            len(overlapping_scenes), len(overlapping_strip_ids)))\n",
    "        \n",
    "        self.overlapping_scenes = overlapping_scenes\n",
    "    \n",
    "    def get_overlapping_strips(self):\n",
    "        return [s for s in self.overlapping_scenes.strip_id.unique().tolist()]\n",
    "\n",
    "    def get_strip_ids(self, scenes):\n",
    "        return[s for s in scenes.strip_id.unique().tolist()]\n",
    "        \n",
    "    def get_good_strip_ids(self, geojson_filename):\n",
    "        strip_downloader = StripDownloader(self.overlapping_scenes,\n",
    "                                           geojson_filename,\n",
    "                                           self.client)\n",
    "        strip_downloader.run(self.udm_asset_type, overwrite=False, verbose=True)\n",
    "        \n",
    "        strip_ids = self.get_overlapping_strips()\n",
    "        udm_strip_mosaics = [strip_downloader.get_filename(i, self.udm_asset_type)\n",
    "                             for i in strip_ids]\n",
    "        \n",
    "        strip_quality = [self._is_good_udm(u) for u in udm_strip_mosaics]\n",
    "        \n",
    "        good_strips = [sid for (sid, squality) in zip(strip_ids, strip_quality) if squality]\n",
    "        return good_strips\n",
    "\n",
    "    def _is_good_udm(self, udm_strip_mosaic):\n",
    "        udm = load_udm(udm_strip_mosaic)\n",
    "        good_percent = ((np.size(udm) - np.count_nonzero(udm)) / np.size(udm)) * 100\n",
    "        return good_percent > 80\n",
    "    \n",
    "    def get_scenes_by_ids(self, strip_ids):\n",
    "        scenes = self.overlapping_scenes.copy()\n",
    "        return scenes[scenes['strip_id'].isin(strip_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_api_key = os.environ['PL_API_KEY']\n",
    "\n",
    "# quick check that key is defined\n",
    "assert planet_api_key, \"PL_API_KEY not defined.\"\n",
    "\n",
    "client = api.ClientV1(api_key=planet_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.planet.com', port=443): Max retries exceeded with url: /data/v1/quick-search (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0f1a7cac18>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 141\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 150\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f0f1a7cac18>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.planet.com', port=443): Max retries exceeded with url: /data/v1/quick-search (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0f1a7cac18>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-201cb952a634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstrip_searcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStripSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgood_scenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeojson_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c063d2d6bb68>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, geojson_filename, use_udm)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeojson_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_udm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_overlapping_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_udm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgeojson_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-c063d2d6bb68>\u001b[0m in \u001b[0;36mget_overlapping_scenes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# get all scenes that fit search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         items = search_pl_api(self.client,\n\u001b[0;32m---> 35\u001b[0;31m                               build_ps_request(self.aoi, self.item_type, self.begin, self.end))\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mscenes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems_to_scenes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} OrthoTiles were returned from the api search.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-27520bb5c516>\u001b[0m in \u001b[0;36msearch_pl_api\u001b[0;34m(client, request, limit)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Utility functions for searching using the Planet data api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_pl_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquick_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# note that this returns a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/planet/api/client.py\u001b[0m in \u001b[0;36mquick_search\u001b[0;34m(self, request, **kw)\u001b[0m\n\u001b[1;32m    161\u001b[0m         return self.dispatcher.response(models.Request(\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/v1/quick-search'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             body_type=models.Items, data=body, method='POST')).get_body()\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msaved_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/planet/api/models.py\u001b[0m in \u001b[0;36mget_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         '''\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/planet/api/dispatch.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, request, callback)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_do_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# @todo delete me w/ v0 removal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/planet/api/dispatch.py\u001b[0m in \u001b[0;36m_do_request\u001b[0;34m(sess, req, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             resp = sess.request(\n\u001b[1;32m    119\u001b[0m                 \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUSE_STRICT_SSL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             )\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# futures session returns futures so only check actual responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/planet/api/dispatch.py\u001b[0m in \u001b[0;36mw\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.planet.com', port=443): Max retries exceeded with url: /data/v1/quick-search (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0f1a7cac18>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))"
     ]
    }
   ],
   "source": [
    "begin=datetime.datetime(year=2017,month=7,day=1)\n",
    "end=datetime.datetime(year=2018,month=3,day=1)\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(geojson_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize scenes and UDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local visual module\n",
    "import visual\n",
    "\n",
    "def load_4band(filename):\n",
    "    with rasterio.open(filename, 'r') as src:\n",
    "        # visual band ordering: red, green, blue, alpha\n",
    "        b, g, r, n = src.read() \n",
    "\n",
    "        # NoData value is 0\n",
    "        mask = b == 0\n",
    "\n",
    "    return [np.ma.array(band, mask=mask) for band in [b, g, r, n]]\n",
    "\n",
    "def visualize_4band(bgrn_bands, title='Orthotile Strip Mosaic', figdim=15):\n",
    "    rgb_bands = [bgrn_bands[i] for i in [2, 1, 0]]\n",
    "    visual.plot_image(rgb_bands, title=title, figsize=(figdim, figdim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate image band arrays for memory conservation\n",
    "def decimate(arry, num=16):\n",
    "    return arry[::num, ::num].copy()\n",
    "\n",
    "def visualize_image_with_udm(strip_downloader, strip_id, asset_type, udm_asset_type):\n",
    "    img_filename = strip_downloader.get_filename(strip_id, asset_type)\n",
    "    img = load_4band(img_filename)\n",
    "    visualize_4band([decimate(b) for b in img], title=strip_id, figdim=5)\n",
    "    \n",
    "    udm_filename = strip_downloader.get_filename(strip_id, udm_asset_type)\n",
    "    udm = decimate(load_udm(udm_filename))\n",
    "    udm_labels = get_udm_labels(udm)\n",
    "    visual.plot_classified_band(udm, class_labels=udm_labels, title=strip_id + ' UDM',\n",
    "                                figdim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = 'analytic'\n",
    "udm_asset_type = 'udm'\n",
    "udm2_asset_type='udm2'\n",
    "\n",
    "strip_downloader = StripDownloader(good_scenes, geojson_filename, client)\n",
    "strip_downloader.run(asset_type, overwrite=False, verbose=True)\n",
    "strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)\n",
    "strip_downloader.run(udm2_asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for strip_id in strip_searcher.get_strip_ids(good_scenes):\n",
    "    visualize_image_with_udm(strip_downloader, strip_id, asset_type, udm_asset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENDED HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for searching for scenes that cover the aoi between given dates\n",
    "def build_ps_request(aoi, item_type, begin, end):\n",
    "    search_aoi = aoi['geometry']\n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(search_aoi),\n",
    "        filters.range_filter('cloud_cover', lt=5),\n",
    "        filters.date_range('acquired', gte=begin),\n",
    "        filters.date_range('acquired', lt=end)\n",
    "    )\n",
    "\n",
    "    # build a request for only PlanetScope imagery\n",
    "    request = filters.build_search_request(\n",
    "        query, item_types=[item_type]\n",
    "    )\n",
    "    \n",
    "    return request\n",
    "\n",
    "def get_monthly_stats(client, request):\n",
    "    stats_request = request.copy()\n",
    "    stats_request['interval'] = 'month'\n",
    "    return client.stats(stats_request).get()\n",
    "\n",
    "begin=datetime.datetime(year=2017,month=7,day=1)\n",
    "end=datetime.datetime(year=2018,month=3,day=1)\n",
    "print(json.dumps(get_monthly_stats(client, build_ps_request(aoi, item_type, begin, end)),\n",
    "      indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "items = list(search_pl_api(client, build_ps_request(aoi, item_type, begin, end)))\n",
    "print(len(items))\n",
    "# uncomment below to see entire metadata for a scene\n",
    "# print(json.dumps(items[0], indent=4))\n",
    "del items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scene data for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_scenes(items):\n",
    "    item_types = []\n",
    "\n",
    "    def _get_props(item):\n",
    "        props = item['properties']\n",
    "        \n",
    "        # add data not in properties list\n",
    "        props.update({\n",
    "            'thumbnail': item['_links']['thumbnail'],\n",
    "            'id': item['id'],\n",
    "            'footprint': item['geometry'],\n",
    "        })\n",
    "        return props\n",
    "    \n",
    "    scenes = pd.DataFrame(data=[_get_props(i) for i in items])\n",
    "    \n",
    "    # convert acquired from string to datetime for processing\n",
    "    scenes['acquired'] = pd.to_datetime(scenes['acquired'])\n",
    "    \n",
    "    return scenes\n",
    "\n",
    "scenes = items_to_scenes(search_pl_api(client, build_ps_request(aoi, item_type, begin, end)))\n",
    "scenes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to scenes with footprints that overlap AOI\n",
    "\n",
    "When the API searches for a scene that overlaps a given AOI, it uses the scene extent. However, we are interested in the scene footprint. That is, we don't care if a portion of a scene with no data overlaps the AOI. We want to filter those scenes out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_intersection(footprint, aoi):\n",
    "    aoi_shape = sgeom.shape(aoi['geometry'])\n",
    "    footprint_shape = sgeom.shape(footprint)\n",
    "    intersection_shape = aoi_shape.intersection(footprint_shape)\n",
    "\n",
    "    try:\n",
    "        intersection_percent = 100 * footprint_shape.area / intersection_shape.area\n",
    "    except ZeroDivisionError:\n",
    "        intersection_percent = 0\n",
    "\n",
    "    data = {'intersection_shape': intersection_shape,\n",
    "            'intersection_fp_perc': intersection_percent}\n",
    "    return pd.Series(data=data)\n",
    "\n",
    "intersections = scenes.footprint.apply(aoi_intersection, args=(aoi,))\n",
    "\n",
    "scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out scenes with no intersection\n",
    "scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "len(scenes_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Overlap\n",
    "\n",
    "Because the AOI straddles orthotile grid lines, we focus on the overlap between the AOI and the strip (which is what is cut into orthotiles).\n",
    "\n",
    "We want to filter to strips that have a significant (80%) overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group scenes by strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "print('{} intersecting strips'.format(scenes_sid.ngroups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(group):\n",
    "    dates = set([a.date() for a in group['acquired']])\n",
    "    assert len(dates) == 1\n",
    "    return min(dates)\n",
    "\n",
    "strip_date = scenes_sid.apply(get_date)\n",
    "strip_date.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate strip overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "# with help from: https://stackoverflow.com/a/43616001/2344416\n",
    "strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=aoi)\n",
    "\n",
    "strip_aoi_inter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the distribution of intersection percent of aoi look like?\n",
    "strip_aoi_inter.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to strips that have significant overlap\n",
    "\n",
    "Here we are defining significant overlap as an overlap of at least 80% of the AOI area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add acquisition date information before filtering\n",
    "strips = strip_aoi_inter.assign(acquisition_date=strip_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to strips that have significant overlap\n",
    "strips_filt = strips[strips.strip_intersection_aoi_perc > 80]\n",
    "print('{} strips with significant overlap'.format(len(strips_filt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the collection dates of strips with significant overlap?\n",
    "strips_filt.acquisition_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to filtering the scene list to scenes in those strips.\n",
    "\n",
    "### Filter to scenes in strips that have significant overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping_strip_ids = strips_filt.index.tolist()\n",
    "# overlapping_strip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to scenes that are in the resulting strips\n",
    "overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} OrthoTiles in {} strips that significantly overlap the aoi.'.format(\n",
    "    len(overlapping_scenes), len(overlapping_strip_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create download function\n",
    "\n",
    "Combine all of the steps above into one function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlapping_scenes(aoi, begin, end, client, item_type, overlap_perc=80):\n",
    "    # get all scenes with overlapping bounds\n",
    "    request = build_ps_request(aoi, item_type, begin, end)\n",
    "    items = search_pl_api(client, request)\n",
    "    scenes = items_to_scenes(items)\n",
    "    print('{} scenes with intersecting borders'.format(len(scenes)))\n",
    "    \n",
    "    # filter to scenes where the footprint overlaps\n",
    "    intersections = scenes.footprint.apply(aoi_intersection, args=(aoi,))\n",
    "    scenes_inter = pd.concat([scenes, intersections], axis=1, sort=False)\n",
    "    scenes_inter = scenes_inter[scenes_inter.intersection_fp_perc > 0]\n",
    "    print('{} scenes with intersecting footprints'.format(len(scenes_inter)))\n",
    "    \n",
    "    # filter to strips with significant overlap\n",
    "    scenes_sid = scenes_inter.groupby(['strip_id'])\n",
    "    strip_aoi_inter = scenes_sid.apply(get_strip_aoi_inter, aoi=aoi)\n",
    "    print('{} intersecting strips'.format(scenes_sid.ngroups))\n",
    "    \n",
    "    strip_date = scenes_sid.apply(get_date)\n",
    "    strips = strip_aoi_inter.assign(acquisition_date=strip_date)\n",
    "    strips_filt = strips[strips.strip_intersection_aoi_perc > overlap_perc]\n",
    "    print('{} strips with significant overlap'.format(len(strips_filt)))\n",
    "    \n",
    "    # filter to scenes that are in resulting strips\n",
    "    overlapping_strip_ids = strips_filt.index.tolist()\n",
    "    overlapping_scenes = scenes[scenes['strip_id'].isin(overlapping_strip_ids)]\n",
    "    \n",
    "    print('There are {} OrthoTiles in {} strips that significantly overlap the aoi'.format(\n",
    "    len(overlapping_scenes), len(overlapping_strip_ids)))\n",
    "    return overlapping_scenes\n",
    "\n",
    "# run again with the same inputs to make sure we get the same results\n",
    "_ = get_overlapping_scenes(aoi, begin, end, client, item_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Scenes Based on Mosaic Scene Usefulness\n",
    "\n",
    "In this section, we create a scene search that filters scenes based on the percentage of useful pixels in the resulting mosaic scene, as determined from the Unusable Data Map (UDM), an asset available alongside the images.\n",
    "\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(geojson_filename)\n",
    "for strip_id in strip_searcher.get_strip_ids(good_scenes):\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Strip Mosaics and UDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate image band arrays for memory conservation\n",
    "def decimate(arry, num=16):\n",
    "    return arry[::num, ::num].copy()\n",
    "\n",
    "def visualize_image_with_udm(strip_downloader, strip_id):\n",
    "    img_filename = strip_downloader.get_filename(strip_id, asset_type)\n",
    "    img = load_4band(img_filename)\n",
    "    visualize_4band([decimate(b) for b in img], title=strip_id, figdim=5)\n",
    "    \n",
    "    udm_filename = strip_downloader.get_filename(strip_id, udm_asset_type)\n",
    "    udm = decimate(load_udm(udm_filename))\n",
    "    udm_labels = get_udm_labels(udm)\n",
    "    visual.plot_classified_band(udm, class_labels=udm_labels, title=strip_id + ' UDM',\n",
    "                                figdim=5)\n",
    "\n",
    "for strip_id in overlapping_strip_ids:\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Mosaic Strip Orthotile COGs\n",
    "\n",
    "Because the AOI crosses over Orthotile grid lines, we need multiple orthotiles from one strip to obtain the image that overlaps the AOI. But the portion of each Orthotile that overlaps the AOI is small relative to the orthotile. Therefore, we only want to download the pixels in the orthotile that overlap the AOI. We will accomplish this by accessing the Orthotiles as Cloud-Optimized Geotiffs (COGs).\n",
    "\n",
    "This is a variation of the COG activation and download performed in `temporal-analysis/crop-temporal.ipynb`. For this notebook, we wait until all orthotiles in a strip are activated then we download the COGs together, using `gdalwarp` to perform the download as well as the mosaicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define asset type\n",
    "\n",
    "For this application, we are interested in the analytic product. This is top-of-atmosphere radiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_type = 'analytic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(aoi_geojson_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get scenes that compose a strip\n",
    "\n",
    "Next we need all the ids for scenes that compose a strip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_id = overlapping_strip_ids[0]\n",
    "print(strip_id)\n",
    "\n",
    "strip_scenes = scenes[scenes['strip_id'] == strip_id]\n",
    "strip_scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate Scenes\n",
    "\n",
    "We use the planet api client [downloader](https://planetlabs.github.io/planet-client-python/api/reference.html#planet.api.downloader.Downloader) to handle activation of the scenes. The downloader handles activation, polling activation status, and (if desired), downloading. Because we are using remote COGs, we do not want to download the scene. However, the downloader can still help us out. It has a cool feature where you can provide it with a function to call when a scene is activated.\n",
    "\n",
    "In this section, we will provide it with a function that records the scene id and download url and checks to see if all scenes in the strip are activated. The function is actually just a method of a class (`Tracker`), which maintains a dataset of scene ids and download urls and a list of scene ids in the strip. The method updates the scene id list when it is called by the downloader. Also, it checks to see if all scenes in the strip have been activated. In the future, we will update this part so that when all scenes in a strip are activated, a download and mosaic is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a downloader that will handle scene activation\n",
    "dl = downloader.create(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This class keeps track of activated scene download urls and the strip scene id's\n",
    "# It also creates the `on_complete` partial function, which can be called\n",
    "# by the downloader to update the list of scene download urls and check to see if all\n",
    "# scenes in the strip are activated\n",
    "class Tracker(object):\n",
    "    def __init__(self, strip_scenes):\n",
    "        self.urls = dict()\n",
    "        self.strip_scenes = set(strip_scenes)\n",
    "        \n",
    "    def get_on_complete(self):\n",
    "        def on_complete(item, asset):\n",
    "            self.urls[item['id']] = asset['location']\n",
    "            print('{}:{}'.format(item['id'], asset['location']))\n",
    "            if self._got_all_strip_scenes():\n",
    "                print('strip complete')\n",
    "        return on_complete\n",
    "    \n",
    "    def _got_all_strip_scenes(self):\n",
    "        return self.strip_scenes.intersection(set(self.urls)) == self.strip_scenes\n",
    "        \n",
    "\n",
    "# create the function that keeps track of the download urls and checks to see if all\n",
    "# scenes in the strip are activated\n",
    "strip_scene_ids = strip_scenes.id.tolist()\n",
    "tracker = Tracker(strip_scene_ids)\n",
    "dl.on_complete = tracker.get_on_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the downloader works with items, so get item object for each scene id\n",
    "strip_scene_items = (client.get_item(item_type, sid).get()\n",
    "                     for sid in strip_scenes.id.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the downloader to activate the scenes and get the download urls\n",
    "dl.shutdown()\n",
    "dl.activate(strip_scene_items, [asset_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and mosaic strip scenes\n",
    "\n",
    "Ok! All scenes in the strip are activated. Now it's time to download them. We are using `gdalwarp` to download the scenes, and it turns out `gdalwarp` is also used for mosaicing scenes, so we are going to download and mosaic the scenes all in one step.\n",
    "\n",
    "### Save aoi as geojson file\n",
    "\n",
    "`gdalwarp` requires the aoi used to crop the COG be saved to disk. We want the AOI to persist in git for use elsewhere so we save it in the `pre-data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_save_dir(root_dir='data'):\n",
    "    save_dir = root_dir\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return save_dir\n",
    "\n",
    "def save_geojson_file(aoi_geojson, save_dir):\n",
    "    filename = os.path.join(save_dir, 'aoi.geojson')\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json.dumps(aoi_geojson))\n",
    "    return filename\n",
    "\n",
    "geojson_filename = save_geojson_file(aoi, create_save_dir('pre-data'))\n",
    "print('wrote AOI to {}'.format(geojson_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output filename\n",
    "\n",
    "`gdalwarp` saves the mosaic to disk and needs a filename for where to save it.\n",
    "\n",
    "We don't want the mosaic images to persist in git so we save them to the `data` folder, which is not tracked in git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_filename(strip_id, save_dir):\n",
    "    create_save_dir(save_dir)\n",
    "    filename = os.path.join(save_dir, strip_id + '_analytic_mosaic.tif')\n",
    "    return filename\n",
    "\n",
    "output_file = create_output_filename(strip_id, 'data')\n",
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and mosaic COGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(item_ids, download_urls) = zip(*tracker.urls.items())\n",
    "item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use gdalwarp to only download the aoi portion of the COGs and mosaic them in one step\n",
    "def _gdalwarp(input_filenames, output_filename, options, verbose=False):\n",
    "    commands = ['gdalwarp'] + options + \\\n",
    "               ['-overwrite'] + \\\n",
    "               input_filenames + \\\n",
    "               [output_filename]\n",
    "    if verbose: print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "\n",
    "# lossless compression of an image\n",
    "def _compress(input_filename, output_filename, verbose=False):\n",
    "    commands = ['gdal_translate',\n",
    "                '-co', 'compress=LZW',\n",
    "                '-co', 'predictor=2',\n",
    "                input_filename,\n",
    "                output_filename]\n",
    "    if verbose: print(' '.join(commands))\n",
    "    subprocess.check_call(commands)\n",
    "\n",
    "def download_strip_aoi(download_urls, output_filename, geojson_filename, compress=True, verbose=False):\n",
    "    vsicurl_urls = ['/vsicurl/' + d for d in download_urls]\n",
    "    options = [\n",
    "        '-cutline', geojson_filename,\n",
    "        '-crop_to_cutline',\n",
    "    ]\n",
    "    \n",
    "    if compress:\n",
    "        with tempfile.NamedTemporaryFile(suffix='.vrt') as vrt_file:\n",
    "            options += ['-of', 'vrt']\n",
    "            _gdalwarp(vsicurl_urls, vrt_file.name, options, verbose=verbose)\n",
    "            _compress(vrt_file.name, output_filename, verbose=verbose)\n",
    "    else:\n",
    "        _gdalwarp(vsicurl_urls, output_filename, options, verbose=verbose)\n",
    "\n",
    "download_strip_aoi(download_urls, 'data/739199_analytic_mosaic_comp.tif', geojson_filename, verbose=True)\n",
    "download_strip_aoi(download_urls, output_file, geojson_filename, compress=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Strip Mosaic Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local visual module\n",
    "import visual\n",
    "\n",
    "def load_4band(filename):\n",
    "    with rasterio.open(filename, 'r') as src:\n",
    "        # visual band ordering: red, green, blue, alpha\n",
    "        b, g, r, n = src.read() \n",
    "\n",
    "        # NoData value is 0\n",
    "        mask = b == 0\n",
    "\n",
    "    return [np.ma.array(band, mask=mask) for band in [b, g, r, n]]\n",
    "\n",
    "def visualize_4band(bgrn_bands, title='Orthotile Strip Mosaic', figdim=15):\n",
    "    rgb_bands = [bgrn_bands[i] for i in [2, 1, 0]]\n",
    "    visual.plot_image(rgb_bands, title=title, figsize=(figdim, figdim))\n",
    "\n",
    "print(output_file)\n",
    "visualize_4band(load_4band(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a beautiful image! It is a little blue due to atmospheric effects. There are a few clouds, but we can clearly see the roads in the forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Mosaic Multiple Strip Orthotile COGs\n",
    "\n",
    "This process is much like the process for downloading and mosaicing a single strip orthotile, but we want to trigger the download as soon as all scenes in a strip are activated. So this will require a bit of a change to the `on_complete()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test downloader with initial strip\n",
    "\n",
    "This should be pretty quick as we have already activated all of these scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_strip_downloader = StripDownloader(strip_scenes, geojson_filename, client)\n",
    "single_strip_downloader.run(asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Strip Mosaic and UDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_4band(load_4band(single_strip_downloader.get_filename(strip_id, asset_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udm_asset_type = 'udm'\n",
    "single_strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Utility functions for loading a UDM image and identifying binary representation as class labels\n",
    "def load_udm(udm_filename):\n",
    "    '''Load single-band bit-encoded UDM as a 2D array.'''\n",
    "    with rasterio.open(udm_filename, 'r') as src:\n",
    "        udm = src.read()[0,...]\n",
    "    return udm\n",
    "\n",
    "def get_udm_labels(udm):\n",
    "    '''Get the binary representation of the UDM values'''\n",
    "    return OrderedDict((v, '{0:08b}'.format(v)) for v in np.unique(udm))\n",
    "\n",
    "udm_filename = single_strip_downloader.get_filename(strip_id, udm_asset_type)\n",
    "udm = load_udm(udm_filename)\n",
    "udm_labels = get_udm_labels(udm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.plot_classified_band(udm, class_labels=udm_labels, title='UDM', figdim=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run downloader on all strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strip_downloader = StripDownloader(overlapping_scenes, geojson_filename, client)\n",
    "strip_downloader.run(asset_type, overwrite=False, verbose=True)\n",
    "strip_downloader.run(udm_asset_type, overwrite=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Strip Mosaics and UDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the UDMs associated with the strip mosaics that clouds cover a significant portion of many mosaics, even though we restricted our search to scenes that had less than 5% clouds. To get decent classification, we should filter our strip scenes by the percentage of good UDM pixels in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for Scenes Based on Mosaic Scene Usefulness\n",
    "\n",
    "In this section, we create a scene search that filters scenes based on the percentage of useful pixels in the resulting mosaic scene, as determined from the Unusable Data Map (UDM), an asset available alongside the images.\n",
    "\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(geojson_filename)\n",
    "for strip_id in strip_searcher.get_strip_ids(good_scenes):\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=datetime.datetime(year=2017,month=9,day=1)\n",
    "end=datetime.datetime(year=2017,month=12,day=1)\n",
    "strip_searcher = StripSearcher(aoi, begin, end, client)\n",
    "good_scenes = strip_searcher.search(geojson_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strip_id in strip_searcher.get_strip_ids(good_scenes):\n",
    "    visualize_image_with_udm(strip_downloader, strip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better! From now on, we will filter by udm when downloading strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
